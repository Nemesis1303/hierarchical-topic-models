{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717da1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tomotopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40abeb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "import pickle\n",
    "import time as timer\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79efaf19-e20d-4d9f-99a0-f2b70fce2d08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mallet_corpus_to_df(corpusFile: pathlib.Path):\n",
    "    \"\"\"Converts a Mallet corpus file (i.e., file required for the Mallet import command) to a pandas DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpusFile: pathlib.Path\n",
    "        Path to the Mallet corpus file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    :   pandas.DataFrame\n",
    "        DataFrame with the corpus\n",
    "    \"\"\"\n",
    "\n",
    "    corpus = [line.rsplit(' 0 ')[1].strip() for line in open(\n",
    "        corpusFile, encoding=\"utf-8\").readlines()]\n",
    "    indexes = [line.rsplit(' 0 ')[0].strip() for line in open(\n",
    "        corpusFile, encoding=\"utf-8\").readlines()]\n",
    "    corpus_dict = {\n",
    "        'id': indexes,\n",
    "        'text': corpus\n",
    "    }\n",
    "    return pd.DataFrame(corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b23bb68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100016</td>\n",
       "      <td>methods processes embedded_systems embed criti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115153</td>\n",
       "      <td>rapid point_care platforms infectious_diseases...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115632</td>\n",
       "      <td>recognise adverse drug reactions regulatory_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115861</td>\n",
       "      <td>vaccine phase_ii sofia_ref main_objective exte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116030</td>\n",
       "      <td>translational quantitative toxicology medicine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65571</th>\n",
       "      <td>190119289</td>\n",
       "      <td>early_detection skin_cancer endure detect skin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65572</th>\n",
       "      <td>190134697</td>\n",
       "      <td>water_vapor turbo compression thermal cool maj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65573</th>\n",
       "      <td>190151860</td>\n",
       "      <td>geotechnical genetic inverse poor track_record...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65574</th>\n",
       "      <td>190161902</td>\n",
       "      <td>artificial_intelligence musical preserve prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65575</th>\n",
       "      <td>190185259</td>\n",
       "      <td>gps free visual line_sight navigation logistic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65576 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text\n",
       "0         100016  methods processes embedded_systems embed criti...\n",
       "1         115153  rapid point_care platforms infectious_diseases...\n",
       "2         115632  recognise adverse drug reactions regulatory_ag...\n",
       "3         115861  vaccine phase_ii sofia_ref main_objective exte...\n",
       "4         116030  translational quantitative toxicology medicine...\n",
       "...          ...                                                ...\n",
       "65571  190119289  early_detection skin_cancer endure detect skin...\n",
       "65572  190134697  water_vapor turbo compression thermal cool maj...\n",
       "65573  190151860  geotechnical genetic inverse poor track_record...\n",
       "65574  190161902  artificial_intelligence musical preserve prese...\n",
       "65575  190185259  gps free visual line_sight navigation logistic...\n",
       "\n",
       "[65576 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_corpus = pathlib.Path(\"/export/usuarios_ml4ds/lbartolome/Datasets/CORDIS/models_preproc/iter_0/corpus.txt\")\n",
    "df = mallet_corpus_to_df(path_corpus)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8022419f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lemas = df[[\"text\"]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dadb966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = tp.TermWeight.ONE # term weighting scheme in TermWeight\n",
    "min_cf = 0             # minimum collection frequency of words.\n",
    "min_df = 0             # minimum document frequency of words.\n",
    "rm_top = 0             # the number of top words to be removed. \n",
    "depth = 4              # the maximum depth level of hierarchy between 2 ~ 32767\n",
    "alpha = 10.0           # hyperparameter of Dirichlet distribution for document-depth level\n",
    "eta = 0.1              # hyperparameter of Dirichlet distribution for topic-word\n",
    "gamma = 1.0            # concentration coeficient of Dirichlet Process\n",
    "seed = None            # random seed\n",
    "mycorpus = df_lemas  \n",
    "transform = None       # a callable object to manipulate arbitrary keyword arguments for a specific topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71dd5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLEGA 1\n",
      "LLEGA 2\n",
      "LLEGA 3\n",
      "Num docs:65576, Num Vocabs:20374, Total Words:4497518\n",
      "Iteration: 0000, LL per word: -9.169\n",
      "Iteration: 0020, LL per word: -8.102\n",
      "Iteration: 0040, LL per word: -8.055\n"
     ]
    }
   ],
   "source": [
    "mdl = tp.HLDAModel(tw = tp.TermWeight.ONE , min_cf= 0, min_df= 0, rm_top = 0, depth = 2, alpha = 10.0, eta = 0.1, gamma = 1.0)\n",
    "\n",
    "print(\"LLEGA 1\")\n",
    "for texts in mycorpus:\n",
    "    mdl.add_doc(texts[0].split())\n",
    "print(\"LLEGA 2\")\n",
    "mdl.train(0)\n",
    "print(\"LLEGA 3\")\n",
    "print('Num docs:{}, Num Vocabs:{}, Total Words:{}'.format(\n",
    "    len(mdl.docs), len(mdl.used_vocabs), mdl.num_words))\n",
    "\n",
    "# Let's train the model\n",
    "for i in range(0, 1000, 20):\n",
    "    print('Iteration: {:04}, LL per word: {:.4}'.format(i, mdl.ll_per_word))\n",
    "    mdl.train(20)\n",
    "print('Iteration: {:04}, LL per word: {:.4}'.format(1000, mdl.ll_per_word))\n",
    "\n",
    "mdl.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3404137",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(mdl.k):\n",
    "    if not mdl.is_live_topic(k): continue\n",
    "    print('Top 10 words of topic #{}'.format(k))\n",
    "    print(mdl.get_topic_words(k, top_n=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e066911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save lda model for reuse\n",
    "hlda_save = 'hlda.bin'\n",
    "mdl.save(hlda_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828bffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load and print\n",
    "#mdl = tp.HLDAModel.load(hlda_save) \n",
    "#for k in range(mdl.k):\n",
    "#    if not mdl.is_live_topic(k): continue\n",
    "#    print('Top 10 words of topic #{}'.format(k))\n",
    "#    print(mdl.get_topic_words(k, top_n=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
